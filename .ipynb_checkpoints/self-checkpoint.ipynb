{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23698deb",
   "metadata": {},
   "source": [
    "# 6기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7c482",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2831f2",
   "metadata": {},
   "source": [
    "## 6-1) numpy 내적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4beb4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8eda2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 열 벡터 (3,1)\n",
    "x = np.array([[1],[2],[3]]) \n",
    "y = np.array([[4],[5],[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb8011cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [2],\n",
       "        [3]]),\n",
       " array([[4],\n",
       "        [5],\n",
       "        [6]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "360eb197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T # (1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90a2e3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a9ec481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32]]\n",
      "[[ 4  8 12]\n",
      " [ 5 10 15]\n",
      " [ 6 12 18]]\n"
     ]
    }
   ],
   "source": [
    "# 스칼라\n",
    "print( x.T @ y ) # (1,3) (3,1) \n",
    "\n",
    "\n",
    "# 3x3 해열\n",
    "print( y @ x.T ) # (3,1) (1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e387804e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y @ x.T).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a0c9d",
   "metadata": {},
   "source": [
    "- 기존 x.T, y 2D 배열 형태 일관성을 유지하는 것이 NumPy의 일반적인 동작입니다. \n",
    "- 내적의 결과또한 NumPy에서 2D 배열 형태로 반환됩니다. \n",
    "- 따라서 x.T @ y의 결과가 array([[32]])로 표시됩니다. \n",
    "- 이것은 2D 배열이지만 내부에는 하나의 스칼라 값 32가 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9471e2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb2ce615",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3]) \n",
    "y = np.array([4,5,6]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8495f931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # 원소의 개수를 3개가진 1차원 배열, 행벡터, 열벡터라고 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e54e897c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (3,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "148513be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (3,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T.shape,y.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb0e62",
   "metadata": {},
   "source": [
    "- NumPy에서 1차원 배열은 일반적으로 행 벡터나 열 벡터와는 다르게 처리됩니다. \n",
    "\n",
    "- 1차원 배열의 `shape` 속성은 `(n,)` 형태로 나타납니다. \n",
    "\n",
    "- 여기서 `n`은 배열의 원소 수를 의미합니다. 따라서 `x = np.array([1, 2, 3])`의 경우 `x.shape`를 실행하면 `(3,)`로 표시되며, 이는 1차원 배열이며 원소가 3개라는 것을 나타냅니다.\n",
    "\n",
    "- 이러한 표기는 NumPy에서의 일반적인 관례입니다. 1차원 배열은 열 벡터나 행 벡터로 간주하지 않고, 간단히 1차원 배열로 처리됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba209a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T @ y, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcec5d4",
   "metadata": {},
   "source": [
    "- x와 y는 원래 열 벡터(column vector)입니다. \n",
    "\n",
    "- 1차원 배열로 표현되어 있더라도 열 벡터의 개념을 가지고 있으며, 전치(transpose) 연산을 수행하더라도 열 벡터의 형태는 변하지 않습니다. \n",
    "\n",
    "- 따라서 내적을 계산할 때 x.T와 y를 내적하든, y와 x.T를 내적하든 결과는 동일하며, 그 결과는 스칼라 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35eb14cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y @ x.T # (3,1) (1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94d72c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b786388",
   "metadata": {},
   "source": [
    "## 선형 독립\n",
    "- 서로 직교하는 영벡터가 아닌 N개의 벡터가 선형독립임을 증명하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edddb0e4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4f100",
   "metadata": {},
   "source": [
    "## 특성방정식, 고윳값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b17ce08",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b45dd",
   "metadata": {},
   "source": [
    "## 확률 변수\n",
    "\n",
    "- 이산형 확률 변수는 확률변수가 가질 수 있는 경우의 수를 모두 고려하여 확률을 ㉠(                 ) 모델링한다. \n",
    "\n",
    "- ㉡(                 )은/는 누적확률분포의 변화율을 모델링하며, ㉡(                 )를 특정 구간에 대하여 정적분하면 이것이 연속형 확률변수가 특정 구간에 포함될 확률이 된다.\n",
    "\n",
    "- 몬테카를로 샘플링 방법은 변수 유형(이산형, 연속형)에 ㉢(                 ) 사용할 수있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec18cbf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed0d83",
   "metadata": {},
   "source": [
    "## 6-5) 정규화 방식(Overfitting)\n",
    "\n",
    "- Overfitting : 오버비팅은 주로 매개변수가 많고 표현력이 높은 모델이나, 훈련 데이터가 적은 경우에 발생한다.\n",
    "\n",
    "- Parameter Norm Penalty : 손실함수에 Norm Penalty Term을 추가하여 사용하여 활용하며 L1 Norm, L2 Norm 등이 있다.\n",
    "\n",
    "- Batch Normalization : 배치 정규화는 초깃값의 영향을 크게 받기 때문에 주의하여야 한다.\n",
    "\n",
    "- Noise Robustness : 레이어 중간에 노이즈를 추가하여 과적합을 해결하는 방법론이다.\n",
    "\n",
    "- Early Stopping : 모델의 과적합을 방지하기 위해 이전 에폭(학습 반복 회수)에 비해 검증 오차(Validation Loss)가 감소하다 증가하는 경우 학습을 종료시킨다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2bb10",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c975ca3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b727e73f",
   "metadata": {},
   "source": [
    "## 신경망 - 활성함수\n",
    "\n",
    "신경망에서 활성함수가 필요한 가장 적절한 이유 : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a04a6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e55928b",
   "metadata": {},
   "source": [
    "## cross-entropy H(P,Q),  KL-divergence KL (X|Y)\n",
    "\n",
    "- 이 때, 주어진 확률분포 P, Q 에 대하여, cross-entropy H(P,Q) 수식을 entropy H(X) 와 KL-divergence KL (X|Y) 로 표현할 수 있는데요. 수식이 아래와 같을 때, cross-entropy와 KL-divergence의 관계를 올바르게 표현한 것은 어떤 것일까요?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73858734",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385cd62d",
   "metadata": {},
   "source": [
    "## 6-8) 경사하강법\n",
    "\n",
    "다음 중 경사하강법에 대한 설명 중 옳지 않은 것을 고르세요.\n",
    "\n",
    "\n",
    "1. 기계학습 문제는 대부분 학습 단계에서 최적의 매개변수(가중치와 편향)를 찾아야 한다. \n",
    "\n",
    "2. 이때, 기울기를 통해 함수의 최솟값, 혹은 가능한 한 작은 값을 찾으려 하는 것을 경사법이라고 한다.\n",
    "\n",
    "3. 미분이 가능한 함수 f에 대해 주어진 점 (x, f(x))에서의 접선의 기울기가 음수라면, x를 증가시키면 함수값 f(x)가 감소한다.\n",
    "\n",
    "4. 경사하강법은 비볼록 함수, 안장점 등에서의 한계점이 존재한다.\n",
    "\n",
    "---\n",
    "\n",
    "5. (x) 경사하강법을 통해 구한 함수의 극소값의 위치는 해당 함수의 최솟값의 위치이다.\n",
    "\n",
    "    - 경사하강법을 통해 구한 함수의 극소값(또는 극대값)의 위치가 해당 함수의 최솟값(또는 최댓값)의 위치인지 여부는 함수의 형태와 경사하강법의 초기 조건에 따라 다릅니다.\n",
    "    - 5-1) 볼록 함수 (Convex Function)의 경우, 경사하강법을 사용하여 구한 함수의 극소값(극소점)의 위치는 해당 함수의 최솟값(전역 최솟값)의 위치와 일치합니다. \n",
    "    - 5-2) 비볼록 함수(Non-convex Function 는 여러 개의 극소점(local minima)을 가질 수 있으며, 경사하강법은 초기 조건에 따라 수렴 지점이 다를 수 있습니다. 초기 조건에 따라 수렴 지점이 다를 수 있으며, 최솟값이 아닌 극소값 지역 최솟값(local minimum)에 수렴할 수도 있습니다. \n",
    "    \n",
    "    - 5-3) 안장점 (Saddle Points): 안장점은 기울기가 0이지만 극소점이나 극대점이 아닌 지점을 가리킵니다. 경사하강법은 안장점에서 기울기가 0이므로 멈출 수 있으며, 전역 최솟값이 아닌 지점에서 수렴할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- 경사 하강법 학습률, 학습 횟수 잘 조절해서 원하는 계수를 찾을 수 있음.\n",
    "- 확률적 경사 하강법 SGD 에서는 학습률, 학습 횟수, 미니 배치 사이즈 까지 고려\n",
    "- 일부 데이터만 사용해서 처리, 처리 속도 빠름. 배치사이즈가 너무 작으면 오히려 늦을 수도 있음\n",
    "- 최소점으로 가는 방향 은 향함\n",
    "- 경사 하강법 처럼, 모든 데이터를 처리하게되면, 메모리가 부족하여 Out of memory 발생\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765b0c96",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2c4ec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171672bd",
   "metadata": {},
   "source": [
    "## 시퀀스 데이터\n",
    "\n",
    "시퀀스 데이터에대한 설명 중 가장 적절한 것을 고르세요.\n",
    "\n",
    "- 대표적인 시퀀스 데이터에는 소리 데이터, 문자열 데이터, 주가 데이터, 이미지 데이터 등이 있다.\n",
    "- 시퀀스 데이터를 학습시켜 모델을 생성하는 시퀀스 모델링은 일대다, 혹은 다대일 모델링만이 가능하다.\n",
    "- RNN의 잠재변수는 다음 순서의 잠재 변수를 모델링하기 위한 입력 값으로 사용될 수 있다.\n",
    "- LSTM의 입력(Input) 게이트는 새로운 정보 중 어떤 것을 버릴 지, 망각(Forget) 게이트는 새로운 정보 중 어떤 것을 저장할 지 결정하게 된다.\n",
    "- 시퀀스의 길이가 길어지는 경우, Vanila RNN에서 발생할 수 있는 기울기 소실 문제를 해결하기 위해 LSTM, GRU, CNN 등의 기법을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc70b7a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463c0d1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a63b0c0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f57193",
   "metadata": {},
   "source": [
    "# 5기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7f436",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850622f",
   "metadata": {},
   "source": [
    "## Overfitting, Underfitting\n",
    "\n",
    "\n",
    "- Overfitting은 훈련 데이터의 개수에 비해 사용하는 모델이 너무 큰 경우 발생할 수 있다.\n",
    "- Underfitting이 일어났을 경우 학습을 더 오래 진행하거나 더 큰 모델을 활용하여 해결 가능하다.\n",
    "- Overfitting이 일어났을 경우 Early Stop 을 적용하면 효과를 볼 수 있다.\n",
    "- Overfitting이 일어난다면 Dropout 기법을 적용하면 효과를 볼 수 있다.\n",
    "\n",
    "-- Overfitting이 일어났을 경우 모델에 regularization method를 적용해본다. (Underfitting x)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Overfitting (과적합)은 모델이 학습 데이터셋을 지나치게 학습하여 발생하는 문제로 학습 데이터셋에서는 성능이 높게 나타나지만, 평가 데이터셋(일반화된 데이터셋)에서 오히려 성능이 더 떨어지는 현상을 의미한다. \n",
    "\n",
    "Overfitting이 발생한다면 훈련데이터를 추가하거나 더 작은 모델을 활용해볼 수 있다. \n",
    "\n",
    "또한, Dropout, Regularization Method, Early Stopping Rule 등등의 방법론을 활용하기도 한다.\n",
    "\n",
    "\n",
    "Underfitting(과소적합)은 Overfitting(과적합)의 반대 개념으로 모델이 충분히 학습 데이터를 학습하지 않은 상태를 의미한다. Underfitting이 발생한다면 학습을 더 오래 진행하거나 더 큰 모델을 활용하여 문제를 해결 할 수 있다.\n",
    "\n",
    "Underfitting이 아닌 Overfitting이 일어났을 경우, 모델에 regularization method를 적용하는 것이 옳기에 정답은 4번이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9fa92",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc212e53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab43f021",
   "metadata": {},
   "source": [
    "## RNN 계열 모델 Vanilla RNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f93d6",
   "metadata": {},
   "source": [
    "## stride, pad, 합성곱 연산, 피처맵 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232e6022",
   "metadata": {},
   "source": [
    "## 시그모이드 함수, 순전파 역전파 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50cc11",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35604d68",
   "metadata": {},
   "source": [
    "## 5-5) 정규화 방식(Overfitting)\n",
    "\n",
    "딥러닝에서는 Overfitting을 방지하기 위해서 다양한 정규화 방법론을 활용합니다.\n",
    "\n",
    "- Dropout은 학습 과정 중 신경망의 뉴런 중 일부를 랜덤하게 부분적으로 생략하는 방법론으로 학습이 진행될 때마다 뉴런을 무작위로 학습하여 매번 모델을 다르게 학습시킨다는 관점에서 앙상블 기법과 유사한 효과를 냅니다.\n",
    "\n",
    "- Parameter Norm Penalty는 L1 Norm, L2 Norm등이 있으며 손실함수에 해당 Norm Penalty Term을 추가적으로 활용하여 정규화를 진행합니다. L1 Norm은 오차의 절댓값을 L2 Norm은 오차 제곱합을 활용합니다.\n",
    "\n",
    "- (x) Batch Normalization(배치 정규화)는 배치단위간에 데이터 분포의 차이가 발생할 수 있기에, 학습 과정에서 각 배치 별로 데이터의 평균과 분산을 이용해 정규화를 진행하는 방법론으로 각 데이터 분포를 평균은 0, 표준편차는 1인 데이터의 분포로 조정합니다.\n",
    "\n",
    "- Noise Robustness는 레이어 중간에 노이즈를 추가하여 학습 효과를 높이고 과적합을 방지하는 방법론이고,\n",
    "\n",
    "- 마지막으로 Early Stopping은 모델의 과적합을 방지하기 위해서 이전 에폭에 비해 검증 오차(Validation Loss)가 감소하다 증가하는 경우 학습을 종료시키는 방법론입니다. 그러므로 정답은 5번입니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb6a7c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7c7d5",
   "metadata": {},
   "source": [
    "## 선형독립, 선형 종속\n",
    "\n",
    "주어진 벡터 집합 v1, v2, ..., vn에 대해 만약 방정식 x1v1 + x2v2 + ⋯ + xnvn = 0을 만족하는 x1, x2, ..., xn이 모두 0이라면, 이 벡터 집합은 선형 독립입니다.\n",
    "\n",
    "\n",
    "선형 독립: 벡터들 v1, v2, ..., vn이 선형 독립인 경우, 방정식 x1v1 + x2v2 + ⋯ + xnvn = 0을 만족하는 x1, x2, ..., xn이 모두 0일 때입니다. \n",
    "\n",
    "다시 말하면, 오직 영벡터만이 주어진 벡터들의 선형 결합으로 나타낼 수 있는 경우입니다. \n",
    "\n",
    "선형 독립인 벡터들은 서로 \"독립적\"이며, 하나의 벡터를 다른 벡터들의 선형 조합으로 나타낼 수 없습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea126e7e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd214b4",
   "metadata": {},
   "source": [
    "##  선형변환 에 대한 표준 행렬\n",
    "\n",
    "1-1). [x1, x2, x3]는 R^3 공간의 벡터이고, [x1 + 2x2, 3x2 - 2x3]는 R^2 공간의 벡터입니다. \n",
    " \n",
    "1-2). 이 선형변환은 R^3에서 R^2로의 매핑을 나타냅니다.\n",
    "\n",
    "2-1). 이 선형변환을 표준행렬로 나타내기 위해, R^3의 표준기저인 e1, e2, e3를 이용하여 T(e1), T(e2), T(e3)을 계산\n",
    "\n",
    "2-2). T(e1) 계산:\n",
    "\n",
    "```\n",
    "T([1, 0, 0]) = [1 + 2 * 0, 3 * 0 - 2 * 0] = [1, 0]\n",
    "\n",
    "T(e2) 계산:\n",
    "T([0, 1, 0]) = [0 + 2 * 1, 3 * 1 - 2 * 0] = [2, 3]\n",
    "\n",
    "T(e3) 계산:\n",
    "T([0, 0, 1]) = [0 + 2 * 0, 3 * 0 - 2 * 1] = [0, -2]\n",
    "````\n",
    "\n",
    "표준행렬 A는 선형변환 T(e1), T(e2), T(e3)을 열 벡터로 가지는 행렬입니다`\n",
    "\n",
    "```\n",
    "A = | 1  2  0 |\n",
    "    | 0  3 -2 |\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b860437",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd6a0d",
   "metadata": {},
   "source": [
    "## 부분공간(Subspace), 기저(Basis), 열 공간(Column Space), 계수(Rank) \n",
    "\n",
    "- 부분공간은 선형 결합에 닫혀있는 벡터공간의 부분집합이다.\n",
    "-  기저는 모든 재료벡터들이 선형 독립이고 해당 벡터들이 부분공간 전체를 표현 가능한 벡터들의 집합을 의미한다.\n",
    "- 열 공간은 행렬의 열 벡터(Column Vector)를 선형결합하여 얻어지는 벡터 공간을 의미한다.\n",
    "- 계수(Rank)는 열 공간의 차원 수를 의미합니다.\n",
    "\n",
    "\n",
    "x 기저는 항상 유일하며 기저를 구성하는 벡터의 개수인 차원(Dimension)도 유일하다.\n",
    "\n",
    " 기저는 벡터 공간에 따라 다를 수 있으며, 기저를 구성하는 벡터의 개수도 다를 수 있습니다. \n",
    " 한 벡터 공간은 여러 가지 서로 다른 기저를 가질 수 있습니다. \n",
    " 기저의 개수는 해당 벡터 공간의 차원을 나타내며, 차원은 유일하지만 기저 자체는 유일하지 않을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d694af",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
